{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76911356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_person_box(img, model):\n",
    "    \"\"\"Use YOLO to detect the largest person box (class 0).\"\"\"\n",
    "    results = model(img)[0]\n",
    "    boxes = results.boxes.xywh.cpu().numpy()\n",
    "    classes = results.boxes.cls.cpu().numpy()\n",
    "\n",
    "    # Filter to person class only\n",
    "    person_boxes = [box for i, box in enumerate(boxes) if int(classes[i]) == 0]\n",
    "\n",
    "    if not person_boxes:\n",
    "        return None\n",
    "\n",
    "    # Choose the largest box (main athlete)\n",
    "    person_boxes = sorted(person_boxes, key=lambda b: b[2] * b[3], reverse=True)\n",
    "    return person_boxes[0]  # [x, y, w, h]\n",
    "\n",
    "def crop_person(img, box):\n",
    "    \"\"\"Crop person bounding box area from image.\"\"\"\n",
    "    x, y, w, h = box\n",
    "    x1, y1 = int(x - w / 2), int(y - h / 2)\n",
    "    x2, y2 = int(x + w / 2), int(y + h / 2)\n",
    "    h_img, w_img = img.shape[:2]\n",
    "\n",
    "    # Clip coordinates to image boundaries\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(w_img, x2), min(h_img, y2)\n",
    "\n",
    "    return img[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53034217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "126bec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, num_frames=20):\n",
    "    \"\"\"Extract `num_frames` evenly spaced frames from the video.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames < num_frames:\n",
    "        num_frames = total_frames  # fallback if video is too short\n",
    "\n",
    "    # Calculate the frame indices to sample\n",
    "    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba402c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aeba7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO(\"yolov8n.pt\")\n",
    "mp_pose = mp.solutions.pose\n",
    "pose_model = mp_pose.Pose(static_image_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b103680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = extract_frames(\"input.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f2d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f2d0451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_joint_angles(landmarks):\n",
    "    # landmarks: shape (33, 4)\n",
    "    return np.zeros(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed4b449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 104.9ms\n",
      "Speed: 2.8ms preprocess, 104.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 baseball bat, 98.5ms\n",
      "Speed: 4.2ms preprocess, 98.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 baseball bat, 81.5ms\n",
      "Speed: 3.7ms preprocess, 81.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 baseball bat, 74.2ms\n",
      "Speed: 3.0ms preprocess, 74.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 baseball bat, 115.3ms\n",
      "Speed: 3.6ms preprocess, 115.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 136.2ms\n",
      "Speed: 4.6ms preprocess, 136.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 149.8ms\n",
      "Speed: 4.3ms preprocess, 149.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 157.8ms\n",
      "Speed: 3.8ms preprocess, 157.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 84.3ms\n",
      "Speed: 5.2ms preprocess, 84.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 84.1ms\n",
      "Speed: 3.4ms preprocess, 84.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 102.0ms\n",
      "Speed: 6.1ms preprocess, 102.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 110.9ms\n",
      "Speed: 3.7ms preprocess, 110.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 sports ball, 96.1ms\n",
      "Speed: 3.5ms preprocess, 96.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 149.8ms\n",
      "Speed: 4.3ms preprocess, 149.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 tennis racket, 97.7ms\n",
      "Speed: 3.1ms preprocess, 97.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 125.5ms\n",
      "Speed: 30.0ms preprocess, 125.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 101.0ms\n",
      "Speed: 4.1ms preprocess, 101.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 95.1ms\n",
      "Speed: 3.9ms preprocess, 95.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 111.1ms\n",
      "Speed: 3.3ms preprocess, 111.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 123.7ms\n",
      "Speed: 5.4ms preprocess, 123.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "sequence = []\n",
    "prev_kps = None\n",
    "for img in frames:\n",
    "        # Detect main person\n",
    "        box = get_main_person_box(img, yolo_model)\n",
    "        if box is None:\n",
    "            keypoints = np.zeros(33 * 4)          # 132 keypoints\n",
    "            joint_angles = np.zeros(6)  # define this\n",
    "            velocities = np.zeros(99)             # 99 velocities\n",
    "            feat_vec = np.concatenate([keypoints, joint_angles, velocities])\n",
    "            sequence.append(feat_vec)\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Crop the main person and feed to MediaPipe\n",
    "        cropped = crop_person(img, box)\n",
    "        img_rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "        results = pose_model.process(img_rgb)\n",
    "\n",
    "        keypoints = []\n",
    "        if not results.pose_landmarks:\n",
    "            continue\n",
    "        kps = np.array([[lm.x, lm.y, lm.z, lm.visibility] for lm in results.pose_landmarks.landmark])\n",
    "        if kps.shape != (33, 4):\n",
    "            continue\n",
    "        kps_flat = kps.flatten()\n",
    "        joint_angles = compute_joint_angles(kps)\n",
    "        # 99 velocities (x,y,z for 33 keypoints)\n",
    "        if prev_kps is None:\n",
    "            velocities = np.zeros(99)\n",
    "        else:\n",
    "            velocities = (kps[:, :3] - prev_kps[:, :3]).flatten()\n",
    "        prev_kps = kps.copy()\n",
    "        feat_vec = np.concatenate([kps_flat, joint_angles, velocities])  # (237,)\n",
    "        sequence.append(feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a58ba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "for x in sequence:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b76ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
